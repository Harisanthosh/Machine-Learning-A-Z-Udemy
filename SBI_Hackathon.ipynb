{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SBI_Hackathon.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harisanthosh/Machine-Learning-A-Z-Udemy/blob/master/SBI_Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5iOHIYuS36G5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c68ec45-1977-4080-be7c-6c6bf9266f0e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fU8U40e-6bW8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Installing dependencies to access Python library"
      ]
    },
    {
      "metadata": {
        "id": "Y6jeN08E5inn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f39e281f-1c3a-4228-8661-92742836fa9f"
      },
      "cell_type": "code",
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.11.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.18.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.2.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.6.8)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.6)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GAycUghQ6kJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4b2f3f1a-3c62-46c0-faa8-3f053b78ca49"
      },
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "!pip install Tkinter"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.2)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.11.0)\n",
            "Collecting Tkinter\n",
            "\u001b[31m  Could not find a version that satisfies the requirement Tkinter (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for Tkinter\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-1EH9zhRA6NH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Validating the twitter credentials"
      ]
    },
    {
      "metadata": {
        "id": "rT-Zgs__60hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "b6a4944b-79be-424b-eed4-9195d502a6ad"
      },
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "from time import sleep\n",
        "from datetime import datetime\n",
        "from textblob import TextBlob #For Sentiment Analysis\n",
        "import matplotlib.pyplot as plt #For Graphing the Data\n",
        "\n",
        "consumer_key = 'q1KmI6l5AWlLB13iBOguFKgLj'\n",
        "consumer_secret = 'Ux2Ya46SjBxRwLKxu2haF6KDSZAt1EdF8AMHe6vPYE2GWWz9Mw'\n",
        "access_token = '149092132-sQqz0y4xCzYjnZGnhsFSL2VguynIZ7FStPh1BmDB'\n",
        "access_token_secret = 'oSNJnMhC2DGGX4DWpQRkDagrvl9i3j35U2mkfCQJAu3nA'\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "public_tweets = api.home_timeline()\n",
        "for tweet in public_tweets:\n",
        "    print(tweet.text)\n",
        "    \n",
        "\n",
        "#Searching for sbi\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT @yvistecomoes: Heladera https://t.co/1FvVvacsyZ\n",
            "Un dato nada menor: en épocas de conflictos internacionales con revistas científicas con precios astronómicos, los… https://t.co/x9WafryfvJ\n",
            "\"Scientists thought they knew Kilauea pretty well. It’s one of the most closely monitored volcanoes in the world, w… https://t.co/8ZiI6zeHtw\n",
            "Paleontólogos trabajando\n",
            "Sitio del hallazgo de Bajadasaurus pronuspinax, una nueva especie de dinosaurio herbívoro… https://t.co/PZWC7F7XfC\n",
            "Bajadasaurus pronuspinax, una nueva especie de dinosaurio herbívoro, fue hallado \"aquí\": en la provincia de Neuquén… https://t.co/7DNM7ZpZKG\n",
            "¿Cómo se ve un fósil de dinosaurio \"aflorando\" de la tierra?\n",
            "Así.\n",
            "#DinosFinDelMundo https://t.co/EQ7RjOmh8H\n",
            "Die Zahl der Beschäftigten des öffentlichen Dienstes in Deutschland ist laut Bundesregierung von gut 4,32 Millionen… https://t.co/4WTaLYcSPB\n",
            "“Esta especie no se destacaba necesariamente por su tamaño sino por otras características anatómicas particulares:… https://t.co/iWUyoxBbbs\n",
            "El nuevo dinosaurio hallado en la Patagonia argentina tenía largas espinas orientadas hacia adelante.\n",
            "@agencia_sinc… https://t.co/a6UjKWd6nE\n",
            "Lo que más sorprendió a los científicos argentinos Pablo Gallina, Sebastián Apesteguía y Juan I. Canale fue esto: e… https://t.co/gKFKZTRWqP\n",
            "Una sonrisa de 140 millones de años\n",
            "Así se veían los dientes de una nueva especie de dinosaurio herbívoro encontrad… https://t.co/DIcGuHdS5e\n",
            "Al norte de la Patagonia argentina, entre los pueblos de Picún Leufú y Piedra del Águila (#Neuquén), hay una zona c… https://t.co/Zvd39wNoWR\n",
            "This year's Faraday lecture looks at possible solutions to engineering's grand challenges, discusses 'thinkering' a… https://t.co/h8H8HNNidn\n",
            "RT @agencia_sinc: Al norte de la Patagonia, un equipo de científicos ha descubierto los restos de una nueva especie de dinosaurio herbívoro…\n",
            "RT @paritosharmaa: Day 19: Learned about the Use of chebysheff’s Theorem to describe the distribution of measurements.\n",
            "#100DaysOfMLCode #10…\n",
            "RT @BoixRichter: Los taxis usan esta coloración para llamar la atención. Es lo que se llama una coloración aposemática. El #taxi quiere que…\n",
            "Sigue creciendo la familia de dinosaurios hallados en Argentina:\n",
            "Bajadasaurus pronuspinax, un increíble herbívoro \"… https://t.co/22cJR7mamk\n",
            "RT @agencia_sinc: La autoría de estudios científicos es la moneda que da más posibilidades de acceder a puestos de trabajo y a fondos para…\n",
            "RT @Harshit9105: Here's a challenge for all hackers - Participate in this #computervision problem (using a real #dataset) and show your ski…\n",
            "The history of the fight against cancer is not over, but this interactive timeline shows how much progress we have… https://t.co/jXk9swWGWb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gBKcXbZMKzCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a Stream Listener class and pass the company's name to access\n",
        "and retrieve the tweet"
      ]
    },
    {
      "metadata": {
        "id": "LZ4TyW-hA92h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyStreamListener(tweepy.StreamListener):\n",
        "\n",
        "    def on_status(self, status):\n",
        "        print(status.text)\n",
        "        \n",
        "    def on_error(self, status_code):\n",
        "        if status_code == 420:\n",
        "            #returning False in on_data disconnects the stream\n",
        "            return False\n",
        "        \n",
        "myStreamListener = MyStreamListener()\n",
        "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n",
        "myStream.filter(track=['sbi'], async=True)                        \n",
        "                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f22ff0cc-5ef2-41d1-9716-f93df88f0fa1",
        "id": "Tf2uTIlAPTt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "import re   \n",
        "def clean_tweet(tweet):\n",
        "  #Removes the @ and RT other special characters from the tweets\n",
        "  return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(^RT)\", \" \", tweet).split())\n",
        "  \n",
        "\n",
        "#query = 'Verizon'\n",
        "print(\"Enter the company name to analyze with commas \\n\")\n",
        "query = input()\n",
        "print(\"Enter the number of latest tweets to scrap\")\n",
        "max_tweets = int(input())\n",
        "model_query = {}\n",
        "companies = query.split(\",\")\n",
        "print(companies)\n",
        "for iter in range(len(companies)):\n",
        "  model_text = []\n",
        "  searched_tweets = [status for status in tweepy.Cursor(api.search, q=companies[iter], tweet_mode='extended').items(max_tweets)]\n",
        "  for i in range(len(searched_tweets)):\n",
        "    model_text.append(clean_tweet(searched_tweets[i].full_text))\n",
        "    #print(model_text[i])\n",
        "  model_query[companies[iter]] = model_text\n",
        "\n",
        "  \n",
        "print(model_query)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the company name to analyze with commas \n",
            "\n",
            "Verizon, Jio, Singtel\n",
            "Enter the number of latest tweets to scrap\n",
            "20\n",
            "['Verizon', ' Jio', ' Singtel']\n",
            "{'Verizon': ['Apple iPhone 8 Plus 64GB Space Gray Verizon A1864 Cracked Front', 'The SuperBowl First Responder commercial by Verizon is beautiful God Bless our first responders', 'how can you really tease me with taco s I can t convince everyone in my family to switch from Verizon', 'Via Verizon s The Team That Wouldn t Be Here ranked 1 in digital share of voice metric amp Xbox We All Win ranked 2 among all Super Bowl TV commercials Congrats to our Microsoft Verizon clients and our two amazing client teams', 'Done RT if you please', 'The top 5 most talked about purpose driven superbowl ads on according to 1 2 3', 'So tired of companies offering donations for RTs especially when their contract with this org probably promises 1 5m re', 'If you re wondering why Verizon just did a commercial honoring first responders this may have something to do with it https', 'If you re wondering why Verizon just did a commercial honoring first responders this may have something to do with it https', 'C Larkin It comes off like a loosely value veiled attempt on a direct dig on CenturyLink honestly I am neither for nor against this as I subscribe to neither company But I do find corporate war entertaining', 'cool thing about the verizon first responder ads they re all because california firefighters emailed them if you dont unt', 'I m so glad that everyone else on reddit is shitting on Verizon after last night', 'Verizon Super Bowl ad honors first responders after wildfire throttling scandal', 'cool thing about the verizon first responder ads they re all because california firefighters emailed them if you dont unt', 'My favorite part of the Super Bowl were the Verizon ads honoring first responders after they throttled firefighters data spe', 'Yep Another favorite Super Bowl commercial honoring first responders CoachLynn', 'Sadly I am a Verizon customer Isn t it funny how a company can be so profit driven that they have no humanity filter It s all about money and more money until someone calls them out on it', 'All connections are important but some are crucial Verizon offers FirstResponders priority voice amp data services so', 'RT amp will donate 1 up to 1 5M in support of first responders to the 1 18 2 8 Join me in g', 'The SuperBowl First Responder commercial by Verizon is beautiful God Bless our first responders'], ' Jio': ['Eveng download pedite inka avvaledu KGF Tuppas ga', 'lighthouse Photo by Nick Jio Subscribe for fresh and original poems Share all you like Comment your thoughts below Westlake Ohio', 'I have just entered the world of Disney on JioCinema Click here', 'Wah Modi Ji wah India USA music NarendraModi incredibleIndia', 'Sir har 3 mahine baad recharge toh zirakpur wale bhi krwate h then yaha apke tower kam or log zada ku Math samajh ni ayai 1 saal se drama chal raha h jiointernetspeed Jio MukeshAmbani failure harrassment BoloGuruji EnoughIsEnough', 'I went to a airtel store DIG bungalow Bhopal to port my Jio sim to Airtel and I was given a sim and was charged 300 for it and later a person named Vivek 9752049104 told he cannot port my sim due to some issues and he didn t return my complete money yet', 'I already have a JIO card amp was using it untill an update to JIO4GVoice app identified my device as VOLTE enabled amp instructed to make calls directly My device is 4G LTE but not VOLTE enabled I had to reluctantly move to Vodafone 3G 4G as I cldnt place calls anymore', '1225 A B A B', 'Yum bbi yak 2019 2 9', 'Wah Modi Ji wah India USA music NarendraModi incredibleIndia', '02 2 9 150 amp rt', 'khemani Wait till Jio switches from beta to full launch You may have some very strong second thoughts', '', '2019 Jio', 'Jio look at the worst 4g network in my neighborhood I live in Akshaya regalia apartment Bangalore Net Velocity couldnt show location on map due to poor connectivity Can you fix this', 'We are here to help you Simply click on the link to DM your Jio number and an alternate number to assist you further Asad', 'Wah Modi Ji wah India USA music NarendraModi incredibleIndia', '1 2 1 http', '2019 Jio', 'D ai n i ng n i nghi ng Y n t m gi s c kh e v ng tr n n m Th m m t m a xu n v ch ng ta c ng th m hi u r ng kh ng g qu h n s c kh e c a ch nh m nh v nh ng ng i th n y u Nh n d p T t K H i 2019'], ' Singtel': ['singtel wtf is wrong with your wifi again at this hour', 'Fixed Satellite Service Market 2019 2025 Global Size Analysis and Market Forecast by Key Players SES Intelsat Eutelsat Communications Telesat SKY Perfect JSAT SingTel Optus Star One Arabsat Hispasat AsiaSat Thaicom via', 'what the FUCK is wrong with singtel again ffs', 'I hate that my family still using singtel Wi Fi at home FML', 'The commercial on youtube made me cry for real', 'Tadi lalu sempadan Singapore Hp direct terus masuk text suru tukar g singtel Aku pon trus flight mode Risau kdt kna tolakk jab g', 'SingTel wifi just shit uh', 'Singtel macam down je', 'Fizz They came over last thursday But appointment was made a week before that maybe', 'Hi need support with my Singtel HI Card', 'Fizz No We called Singtel support around 2pm A technician said our connection is working fine and the problem lies with the network', 'Hi there saw your tweet Need any help', 'Hi there have you tried any basic troubleshooting yet', 'Sahgiel Hi there under IMDA s national numbering plan 1800 is the prefix for local toll free service However calling a 1800 number is toll free only if the call is made from a fixed line Airtime charges would apply for mobile calls made to 1800 local toll free service numbers', 'Hi there saw your tweet Need any help', 'SingTel is betting E Sports will spice up its image via', 'That s odd We haven t had any reports on this Are there any red LED lights flashing on your modem', 'Hi there can I confirm if you were trying to access our website If so which page did this occur at', 'My SingTel wifi has been wonky these few days Is it just me or', 'No red lights Singtel TV Internet and home telephone all down']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s5ykkZBgvbFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        },
        "outputId": "a4ee7040-a9cd-4d14-b7d8-ace9b06ac03b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#Get Tweets Sentiment, if greater than 0 then positive, if 0 it is neutral, if it is less than zero then the tweet is negative\n",
        "def get_sentiment(tweet_str):\n",
        "  analysis = TextBlob(tweet_str)\n",
        "  print(analysis.sentiment)\n",
        "  return analysis.sentiment.polarity\n",
        "\n",
        "model_sentiment = {}\n",
        "company_score = {} #-1 is more likely to default, +1 is in a good health and will not default\n",
        "for key,value in model_query.items():\n",
        "  \n",
        "  score = 0 \n",
        "  \n",
        "  for i in range(len(value)):\n",
        "    model_sentiment[value[i]] = get_sentiment(value[i])\n",
        "    \n",
        "  for key1,value1 in model_sentiment.items():\n",
        "    score += value1\n",
        "    \n",
        "  company_score[key] = score  \n",
        "  \n",
        "print(company_score)\n",
        "  \n",
        "       "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.3375, subjectivity=0.41666666666666663)\n",
            "Sentiment(polarity=0.2, subjectivity=0.2)\n",
            "Sentiment(polarity=0.43333333333333335, subjectivity=0.4916666666666667)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.5, subjectivity=0.5)\n",
            "Sentiment(polarity=-0.2, subjectivity=0.85)\n",
            "Sentiment(polarity=0.125, subjectivity=0.16666666666666666)\n",
            "Sentiment(polarity=0.125, subjectivity=0.16666666666666666)\n",
            "Sentiment(polarity=0.2246153846153846, subjectivity=0.45384615384615384)\n",
            "Sentiment(polarity=0.3, subjectivity=0.4916666666666667)\n",
            "Sentiment(polarity=0.25, subjectivity=0.5333333333333333)\n",
            "Sentiment(polarity=0.29166666666666663, subjectivity=0.5)\n",
            "Sentiment(polarity=0.3, subjectivity=0.4916666666666667)\n",
            "Sentiment(polarity=0.3611111111111111, subjectivity=0.6666666666666666)\n",
            "Sentiment(polarity=0.2708333333333333, subjectivity=0.49999999999999994)\n",
            "Sentiment(polarity=0.08333333333333333, subjectivity=0.8333333333333334)\n",
            "Sentiment(polarity=0.16666666666666666, subjectivity=0.6666666666666666)\n",
            "Sentiment(polarity=0.25, subjectivity=0.3333333333333333)\n",
            "Sentiment(polarity=0.3375, subjectivity=0.41666666666666663)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.3375, subjectivity=0.625)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=-0.3166666666666667, subjectivity=0.3)\n",
            "Sentiment(polarity=-0.008333333333333331, subjectivity=0.25833333333333336)\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.30444444444444446, subjectivity=0.5011111111111112)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=-0.2777272727272727, subjectivity=0.495)\n",
            "Sentiment(polarity=0.0, subjectivity=0.28571428571428575)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=-0.5, subjectivity=0.95)\n",
            "Sentiment(polarity=0.275, subjectivity=0.55)\n",
            "Sentiment(polarity=-0.45, subjectivity=0.75)\n",
            "Sentiment(polarity=-0.8, subjectivity=0.9)\n",
            "Sentiment(polarity=0.1, subjectivity=0.15000000000000002)\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "Sentiment(polarity=-0.2, subjectivity=0.8)\n",
            "Sentiment(polarity=-0.15555555555555559, subjectivity=0.2888888888888889)\n",
            "Sentiment(polarity=0.0, subjectivity=0.06666666666666667)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.4166666666666667, subjectivity=0.5)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.125)\n",
            "Sentiment(polarity=0.18571428571428572, subjectivity=0.5142857142857143)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=-0.08333333333333333, subjectivity=0.125)\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n",
            "Sentiment(polarity=-0.25, subjectivity=0.2)\n",
            "Sentiment(polarity=-0.07777777777777779, subjectivity=0.14444444444444446)\n",
            "{'Verizon': 3.5940598290598293, ' Jio': 3.7332770007770004, ' Singtel': 2.293991286491286}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5MfdB93wSx9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fedbe7c-13d6-4da4-f7fb-7505ae15292b"
      },
      "cell_type": "code",
      "source": [
        "#print(\"Score for the company {0}\".format(score))\n",
        "for key2,value2 in company_score.items():\n",
        "  avg_score = value2 / max_tweets\n",
        "  company_score[key2] = avg_score\n",
        "print(company_score)\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Verizon': 0.17970299145299146, ' Jio': 0.18666385003885003, ' Singtel': 0.1146995643245643}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}